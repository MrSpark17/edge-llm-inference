# Model Configuration
MODEL_NAME=deepscaler-chat

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000

# Inference Configuration
MAX_INPUT_LENGTH=512
INFERENCE_TIMEOUT_SECONDS=5

# Memory Configuration
MAX_MEMORY_MB=2048
MEMORY_WARNING_THRESHOLD_MB=1800

# Intent Classification Configuration
INTENT_CONFIDENCE_THRESHOLD=0.7

# Logging Configuration
LOG_LEVEL=INFO
LOG_FILE=inference.log

# Performance Configuration
ENABLE_PERFORMANCE_MONITORING=true
BATCH_PROCESSING_ENABLED=true
MAX_BATCH_SIZE=32

# Environment Configuration
ENVIRONMENT=development
